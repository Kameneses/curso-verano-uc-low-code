{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizamos un modelo ligero de clasificaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n-cls.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/4 /Users/carlosmeneses/Projects/yolov8/data/test/dog/1.jpg: 224x224 whippet 0.22, Italian_greyhound 0.21, kelpie 0.06, toy_terrier 0.06, Labrador_retriever 0.06, 24.0ms\n",
      "image 2/4 /Users/carlosmeneses/Projects/yolov8/data/test/dog/2.jpg: 224x224 American_Staffordshire_terrier 0.52, Staffordshire_bullterrier 0.35, boxer 0.05, Rhodesian_ridgeback 0.03, bull_mastiff 0.02, 22.4ms\n",
      "image 3/4 /Users/carlosmeneses/Projects/yolov8/data/test/dog/3.jpg: 224x224 golden_retriever 0.30, Norfolk_terrier 0.17, Dandie_Dinmont 0.13, otterhound 0.11, Great_Pyrenees 0.07, 10.4ms\n",
      "image 4/4 /Users/carlosmeneses/Projects/yolov8/data/test/dog/4.jpg: 224x224 Pembroke 0.32, golden_retriever 0.19, chow 0.14, Pomeranian 0.12, collie 0.04, 9.4ms\n",
      "Speed: 2.1ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns/classify/predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(source=\"data/test/dog/\", save=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya disponemos de suficientes categorias entrenadas pero vamos a intentar ejecutar un reentrenamiento con nuestros datos de train. Requiere esta estructura de carpetas \n",
    "\n",
    "```\n",
    "root/\n",
    "|-- class1/\n",
    "|   |-- img1.jpg\n",
    "|   |-- img2.jpg\n",
    "|   |-- ...\n",
    "|\n",
    "|-- class2/\n",
    "|   |-- img1.jpg\n",
    "|   |-- img2.jpg\n",
    "|   |-- ...\n",
    "|\n",
    "|-- class3/\n",
    "|   |-- img1.jpg\n",
    "|   |-- img2.jpg\n",
    "|   |-- ...\n",
    "|\n",
    "|-- ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.134 ðŸš€ Python-3.8.12 torch-2.0.1 CPU\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=data, epochs=10, patience=50, batch=64, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/classify/train\n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1440850 parameters, 1440850 gradients\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       1/10         0G     0.3779         53        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [06:00<00:00,  4.68s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.04it/s]\n",
      "                   all          1          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       2/10         0G     0.0521         53        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [06:46<00:00,  5.28s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.78it/s]\n",
      "                   all          1          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       3/10         0G    0.01393         64        320:   4%|â–         | 3/77 [00:25<10:20,  8.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m YOLO(\u001b[39m\"\u001b[39m\u001b[39myolov8n-cls.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, imgsz\u001b[39m=\u001b[39;49m\u001b[39m320\u001b[39;49m, batch\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Projects/yolov8/venv/lib/python3.8/site-packages/ultralytics/yolo/engine/model.py:373\u001b[0m, in \u001b[0;36mYOLO.train\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[1;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    374\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m~/Projects/yolov8/venv/lib/python3.8/site-packages/ultralytics/yolo/engine/trainer.py:192\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[1;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[0;32m~/Projects/yolov8/venv/lib/python3.8/site-packages/ultralytics/yolo/engine/trainer.py:339\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtloss \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtloss \u001b[39m*\u001b[39m i \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_items) \u001b[39m/\u001b[39m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \\\n\u001b[1;32m    336\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_items\n\u001b[1;32m    338\u001b[0m \u001b[39m# Backward\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaler\u001b[39m.\u001b[39;49mscale(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    341\u001b[0m \u001b[39m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[39mif\u001b[39;00m ni \u001b[39m-\u001b[39m last_opt_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccumulate:\n",
      "File \u001b[0;32m~/Projects/yolov8/venv/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/yolov8/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n-cls.pt\")\n",
    "model.train(data='data', epochs=10, imgsz=320, batch=64, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/4 /Users/carlosmeneses/Projects/yolov8/data/test/dog/1.jpg: 320x320 dog 1.00, cat 0.00, 19.2ms\n",
      "image 2/4 /Users/carlosmeneses/Projects/yolov8/data/test/dog/2.jpg: 320x320 dog 1.00, cat 0.00, 17.9ms\n",
      "image 3/4 /Users/carlosmeneses/Projects/yolov8/data/test/dog/3.jpg: 320x320 dog 1.00, cat 0.00, 16.0ms\n",
      "image 4/4 /Users/carlosmeneses/Projects/yolov8/data/test/dog/4.jpg: 320x320 dog 1.00, cat 0.00, 19.9ms\n",
      "Speed: 1.8ms preprocess, 18.2ms inference, 0.1ms postprocess per image at shape (1, 3, 320, 320)\n",
      "Results saved to \u001b[1mruns/classify/predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.yolo.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " keys: ['probs']\n",
       " masks: None\n",
       " names: {0: 'cat', 1: 'dog'}\n",
       " orig_img: array([[[ 94,  64,  37],\n",
       "         [ 92,  62,  35],\n",
       "         [ 95,  60,  34],\n",
       "         ...,\n",
       "         [201, 107,  71],\n",
       "         [175,  86,  49],\n",
       "         [173,  85,  48]],\n",
       " \n",
       "        [[ 98,  68,  41],\n",
       "         [ 96,  66,  39],\n",
       "         [ 98,  63,  37],\n",
       "         ...,\n",
       "         [200, 106,  71],\n",
       "         [174,  85,  48],\n",
       "         [172,  84,  47]],\n",
       " \n",
       "        [[102,  72,  45],\n",
       "         [100,  70,  43],\n",
       "         [101,  66,  40],\n",
       "         ...,\n",
       "         [199, 105,  70],\n",
       "         [173,  83,  48],\n",
       "         [171,  83,  47]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[172, 169, 165],\n",
       "         [175, 170, 167],\n",
       "         [179, 174, 171],\n",
       "         ...,\n",
       "         [ 70,  89,  96],\n",
       "         [ 56,  78,  84],\n",
       "         [ 54,  77,  85]],\n",
       " \n",
       "        [[173, 172, 168],\n",
       "         [174, 173, 169],\n",
       "         [180, 175, 172],\n",
       "         ...,\n",
       "         [ 90, 107, 116],\n",
       "         [ 74,  97, 105],\n",
       "         [ 75,  97, 108]],\n",
       " \n",
       "        [[178, 177, 173],\n",
       "         [177, 176, 172],\n",
       "         [180, 175, 172],\n",
       "         ...,\n",
       "         [ 99, 116, 125],\n",
       "         [ 84, 107, 115],\n",
       "         [ 85, 107, 118]]], dtype=uint8)\n",
       " orig_shape: (499, 381)\n",
       " path: '/Users/carlosmeneses/Projects/yolov8/data/test/dog/1.jpg'\n",
       " probs: ultralytics.yolo.engine.results.Probs object\n",
       " save_dir: 'runs/classify/predict'\n",
       " speed: {'preprocess': 3.8640499114990234, 'inference': 19.181013107299805, 'postprocess': 0.28204917907714844},\n",
       " ultralytics.yolo.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " keys: ['probs']\n",
       " masks: None\n",
       " names: {0: 'cat', 1: 'dog'}\n",
       " orig_img: array([[[ 25,  27,  62],\n",
       "         [ 24,  26,  61],\n",
       "         [ 24,  26,  61],\n",
       "         ...,\n",
       "         [ 47,  64, 107],\n",
       "         [ 55,  78, 124],\n",
       "         [ 60,  83, 131]],\n",
       " \n",
       "        [[ 29,  31,  66],\n",
       "         [ 29,  31,  66],\n",
       "         [ 28,  30,  65],\n",
       "         ...,\n",
       "         [ 48,  65, 108],\n",
       "         [ 52,  75, 121],\n",
       "         [ 55,  78, 126]],\n",
       " \n",
       "        [[ 35,  35,  71],\n",
       "         [ 33,  33,  69],\n",
       "         [ 31,  31,  67],\n",
       "         ...,\n",
       "         [ 40,  56, 102],\n",
       "         [ 40,  62, 110],\n",
       "         [ 42,  65, 115]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[171, 209, 239],\n",
       "         [160, 198, 230],\n",
       "         [165, 200, 240],\n",
       "         ...,\n",
       "         [ 34,  32,  61],\n",
       "         [ 26,  24,  53],\n",
       "         [ 40,  38,  67]],\n",
       " \n",
       "        [[172, 210, 240],\n",
       "         [162, 200, 232],\n",
       "         [168, 203, 243],\n",
       "         ...,\n",
       "         [ 35,  33,  62],\n",
       "         [ 27,  25,  54],\n",
       "         [ 42,  40,  69]],\n",
       " \n",
       "        [[175, 211, 241],\n",
       "         [166, 201, 234],\n",
       "         [173, 205, 246],\n",
       "         ...,\n",
       "         [ 34,  34,  64],\n",
       "         [ 29,  27,  57],\n",
       "         [ 44,  42,  72]]], dtype=uint8)\n",
       " orig_shape: (299, 296)\n",
       " path: '/Users/carlosmeneses/Projects/yolov8/data/test/dog/2.jpg'\n",
       " probs: ultralytics.yolo.engine.results.Probs object\n",
       " save_dir: 'runs/classify/predict'\n",
       " speed: {'preprocess': 1.146078109741211, 'inference': 17.91095733642578, 'postprocess': 0.030040740966796875},\n",
       " ultralytics.yolo.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " keys: ['probs']\n",
       " masks: None\n",
       " names: {0: 'cat', 1: 'dog'}\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (299, 300)\n",
       " path: '/Users/carlosmeneses/Projects/yolov8/data/test/dog/3.jpg'\n",
       " probs: ultralytics.yolo.engine.results.Probs object\n",
       " save_dir: 'runs/classify/predict'\n",
       " speed: {'preprocess': 1.2331008911132812, 'inference': 15.959978103637695, 'postprocess': 0.027894973754882812},\n",
       " ultralytics.yolo.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " keys: ['probs']\n",
       " masks: None\n",
       " names: {0: 'cat', 1: 'dog'}\n",
       " orig_img: array([[[ 81, 170,  90],\n",
       "         [ 96, 189, 108],\n",
       "         [102, 199, 119],\n",
       "         ...,\n",
       "         [ 73, 143,  90],\n",
       "         [ 50, 122,  69],\n",
       "         [ 73, 148,  94]],\n",
       " \n",
       "        [[ 72, 161,  81],\n",
       "         [ 97, 190, 109],\n",
       "         [ 77, 176,  96],\n",
       "         ...,\n",
       "         [ 18,  89,  33],\n",
       "         [ 81, 153, 100],\n",
       "         [121, 196, 140]],\n",
       " \n",
       "        [[ 83, 174,  95],\n",
       "         [ 91, 183, 104],\n",
       "         [ 37, 136,  56],\n",
       "         ...,\n",
       "         [  0,  60,   2],\n",
       "         [ 37, 112,  56],\n",
       "         [ 37, 114,  56]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 37, 158,  77],\n",
       "         [ 65, 186, 106],\n",
       "         [ 34, 154,  76],\n",
       "         ...,\n",
       "         [ 66, 160, 103],\n",
       "         [ 53, 146,  91],\n",
       "         [ 17, 109,  56]],\n",
       " \n",
       "        [[ 59, 180,  96],\n",
       "         [ 55, 177,  93],\n",
       "         [ 24, 145,  65],\n",
       "         ...,\n",
       "         [ 85, 160, 106],\n",
       "         [ 44, 117,  67],\n",
       "         [ 57, 129,  82]],\n",
       " \n",
       "        [[ 24, 145,  60],\n",
       "         [ 11, 132,  48],\n",
       "         [ 72, 193, 112],\n",
       "         ...,\n",
       "         [102, 166, 114],\n",
       "         [ 81, 146,  97],\n",
       "         [ 27,  91,  45]]], dtype=uint8)\n",
       " orig_shape: (288, 374)\n",
       " path: '/Users/carlosmeneses/Projects/yolov8/data/test/dog/4.jpg'\n",
       " probs: ultralytics.yolo.engine.results.Probs object\n",
       " save_dir: 'runs/classify/predict'\n",
       " speed: {'preprocess': 1.1069774627685547, 'inference': 19.91415023803711, 'postprocess': 0.023603439331054688}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(source=\"data/test/dog/\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
